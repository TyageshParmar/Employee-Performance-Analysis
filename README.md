# Employee-Performance-Analysis
# Employee Performance Prediction

## ğŸ“Œ **Project Overview**
This project aims to predict employee performance ratings at **INX Future Inc.** using **machine learning and deep learning models**. The dataset includes various features such as **work experience, job satisfaction, training history, and work-life balance** to analyze and improve employee performance.

## ğŸ“‚ **Dataset Information**
- **Source:** INX Future Inc Employee Performance Dataset
- **Features:** 27 columns (Employee Demographics, Job Role, Work Environment, etc.)
- **Target Variable:** `PerformanceRating` (Categorical: 2, 3, or 4)
- **Challenges:** The dataset is **imbalanced**, requiring techniques like **SMOTE** and **class weighting**.

## ğŸš€ **Technologies Used**
- **Programming Language:** Python
- **Libraries & Tools:** Pandas, NumPy, Scikit-Learn, TensorFlow, Keras, Matplotlib, Seaborn
- **Machine Learning Models:** Logistic Regression, Random Forest, SVM, NaÃ¯ve Bayes, Gradient Boosting, XGBoost and many more...
- **Deep Learning:** Artificial Neural Network (ANN) with Hyperparameter Tuning
- **Hyperparameter Tuning:** GridSearchCV, RandomizedSearchCV

## ğŸ† **Best Performing Model**
| Model | HPT Training Accuracy | HPT Testing Accuracy | Overfitting Risk |
|--------|----------------------|----------------------|------------------|
| **Gradient Boosting** | **100.00%** | **95.73%** | âœ… Low (Minimal overfitting) |
| **Ensemble Model** | 99.59% | 96.49% | âœ… Low (Balanced performance) |
| **Random Forest** | 100.00% | 96.18% | âœ… Low (Minimal overfitting) |
| **Support Vector Machine (SVM)** | 99.54% | 94.66% | âœ… Low (Good improvement after tuning) |
| **Ada Boosting** | 91.04% | 91.00% | âœ… Low (Stable model) |
|	**Xtreme Gradient Boosting** |	99.69% |	96.18% | âœ… Low (Minimal overfitting) |
|	**Bagging Algorithm** |	99.33% |	94.96% | âœ… Low (Minimal overfitting) |
|	**Neural Network** |	98.21% |	91.46% | âœ… Low (Minimal overfitting) |

## âš ï¸ **Challenges Faced**
### **1ï¸âƒ£ Data Quality and Preparation**
âœ” Handling missing values and categorical encoding
âœ” Addressing class imbalance with SMOTE & class weighting
âœ” Feature selection using correlation analysis and mutual information

### **2ï¸âƒ£ Model Selection and Hyperparameter Tuning**
âœ” Avoiding overfitting in complex models (ANN, Decision Tree)
âœ” Reducing computational costs of ensemble methods
âœ” Finding the right balance between accuracy and generalization

### **3ï¸âƒ£ Performance Evaluation & Overfitting Prevention**
âœ” Used **confusion matrix, classification report, and accuracy curves**
âœ” Applied **dropout, early stopping, and L2 regularization** for deep learning
âœ” Compared models based on **generalization ability** (train vs. test accuracy)

## ğŸ”§ **Installation & Setup**
1. Clone the repository:
   ```sh
   git clone https://github.com/your-username/employee-performance-prediction.git
   cd employee-performance-prediction
   ```
2. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```
3. Run the project:
   ```sh
   python main.py
   ```

## ğŸ“Š **Results & Insights**
âœ” **Job satisfaction & work-life balance strongly influence performance**
âœ” **Recent promotions & salary hikes impact retention & productivity**
âœ” **Overtime & training frequency correlate with higher performance ratings**
âœ” **Feature engineering & balancing techniques significantly improve model accuracy**
âœ” **Neural Networks showed potential but required extensive tuning to generalize well**

## ğŸ“Œ **Future Enhancements**
ğŸ”¹ Implement **Explainable AI (XAI)** to interpret model decisions
ğŸ”¹ Deploy the model using **Flask/Django API** for real-time predictions
ğŸ”¹ Expand dataset with **employee feedback & additional performance metrics**
ğŸ”¹ Further optimize deep learning models with **transfer learning & advanced architectures**

## ğŸ‘¨â€ğŸ’» **Contributors**
- [Tyagesh Parmar]([https://github.com/your-username](https://github.com/TyageshParmar/Employee-Performance-Analysis))
